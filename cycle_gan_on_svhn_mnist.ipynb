{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.CycleGan import CycleGan\n",
    "from models.SHVN_MNIST_dataset import ShvnMnistDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "accelerator = \"cpu\"\n",
    "devices = 1\n",
    "max_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./Data/svhn/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "root = \"./Data\"\n",
    "train = ShvnMnistDataset(root, 'train')\n",
    "train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "model = CycleGan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/shuagarw/repos/cyclegans/lightning_logs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39maccelerator, devices\u001b[38;5;241m=\u001b[39mdevices, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=517'>518</a>\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=518'>519</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=519'>520</a>\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=520'>521</a>\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=521'>522</a>\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py?line=41'>42</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py?line=42'>43</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py?line=43'>44</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py?line=45'>46</a>\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py?line=46'>47</a>\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=548'>549</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=549'>550</a>\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=550'>551</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=552'>553</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=553'>554</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=554'>555</a>\u001b[0m     ckpt_path,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=555'>556</a>\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=556'>557</a>\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=557'>558</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=558'>559</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=560'>561</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=561'>562</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:911\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=907'>908</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=909'>910</a>\u001b[0m \u001b[39m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=910'>911</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=912'>913</a>\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=913'>914</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, trainer: pl\u001b[39m.\u001b[39mTrainer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py?line=72'>73</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py?line=73'>74</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msetup(trainer)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:148\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=145'>146</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=146'>147</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39msetup(trainer)\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=147'>148</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_optimizers(trainer)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=148'>149</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=149'>150</a>\u001b[0m _optimizers_to_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:138\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=135'>136</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=136'>137</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py?line=137'>138</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler_configs \u001b[39m=\u001b[39m _init_optimizers_and_lr_schedulers(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:185\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=178'>179</a>\u001b[0m optimizers, lr_schedulers, monitor \u001b[39m=\u001b[39m _configure_optimizers(optim_conf)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=179'>180</a>\u001b[0m lr_scheduler_configs \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=180'>181</a>\u001b[0m     _configure_schedulers_automatic_opt(lr_schedulers, monitor)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=181'>182</a>\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mautomatic_optimization\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=182'>183</a>\u001b[0m     \u001b[39melse\u001b[39;00m _configure_schedulers_manual_opt(lr_schedulers)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=183'>184</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=184'>185</a>\u001b[0m _validate_multiple_optimizers_support(optimizers, model)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=185'>186</a>\u001b[0m _validate_optimizers_attached(optimizers, lr_scheduler_configs)\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=186'>187</a>\u001b[0m _validate_scheduler_api(lr_scheduler_configs, model)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:341\u001b[0m, in \u001b[0;36m_validate_multiple_optimizers_support\u001b[0;34m(optimizers, model)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=338'>339</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_multiple_optimizers_support\u001b[39m(optimizers: List[Optimizer], model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=339'>340</a>\u001b[0m     \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mautomatic_optimization \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(optimizers) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=340'>341</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=341'>342</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTraining with multiple optimizers is only supported with manual optimization. Set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=342'>343</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `self.automatic_optimization = False`, then access your optimizers in `training_step` with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=343'>344</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `opt1, opt2, ... = self.optimizers()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/anaconda3/envs/dgm/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py?line=344'>345</a>\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Training with multiple optimizers is only supported with manual optimization. Set `self.automatic_optimization = False`, then access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=accelerator, devices=devices, max_epochs=max_epochs)\n",
    "trainer.fit(model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15bb87710bc6ec9f167469a41139a1243c978bc460abede3abe5901f6348c029"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('dgm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
